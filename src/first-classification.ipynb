{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "mobile-insertion",
   "metadata": {},
   "source": [
    "# Première classification\n",
    "\n",
    "L'objectif ici est d'utiliser un premier classifier. Pour commencer nous prendrons SVM qui obtient souvent de bons résultats sur les données textuelles.\n",
    "\n",
    "Nous pouvons donc, pour simplifier, créer un jeu d'apprentissage et un jeu de test et évaluer le résultat d'un classifieur SVM placé dans un pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "brutal-blanket",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pretraitement import TextPreTraitement\n",
    "from clean import clean_claimKG\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "generic-imagination",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = \"../data/claimKG.csv\"\n",
    "origin = pd.read_csv(file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "hindu-provider",
   "metadata": {},
   "outputs": [],
   "source": [
    "kg = origin.copy()\n",
    "\n",
    "kg = clean_claimKG(kg, verbose=False, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "exceptional-butterfly",
   "metadata": {},
   "source": [
    "Pour un premier test, nous allons prendre comme `X` les assertions et `Y` les valeurs de véracité.\n",
    "\n",
    "Note: les valeurs de véracité ne sont pour l'instant pas disponible, à voir ou les trouver.\n",
    "\n",
    "Donc, pour l'instant, on ne garde que les lignes qu'on peut exploiter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dynamic-conversion",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    10701\n",
      "2    10258\n",
      "1     4584\n",
      "Name: ratingValue, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "def translate(rating):\n",
    "    t = {'false': 0,\n",
    "        'true': 1,\n",
    "        'mixture': 2,\n",
    "        'other': -1,\n",
    "        'mostly true': 2,\n",
    "        'mostly false': 2,\n",
    "        'half-true': 2,\n",
    "    }\n",
    "    return t[rating]\n",
    "    \n",
    "# mettre toutes les valeurs en miniscule\n",
    "kg['rating_alternateName'] = kg['rating_alternateName'].apply(lambda x : str(x).lower())\n",
    "\n",
    "keep = ['false', 'true', 'mostly false', 'mostly true','half-true', 'mixture']\n",
    "keep_lst = kg.index[kg['rating_alternateName'].isin(keep)].tolist()\n",
    "# print(kg.loc[keep_lst]['rating_alternateName'].value_counts())\n",
    "\n",
    "rm_lst = kg.index[~kg['rating_alternateName'].isin(keep)].tolist()\n",
    "kg.drop(rm_lst, inplace=True)\n",
    "kg['ratingValue'] = kg['rating_alternateName'].apply(lambda x: translate(x))\n",
    "print(kg['ratingValue'].value_counts())\n",
    "del rm_lst, keep_lst, translate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "corrected-gravity",
   "metadata": {},
   "source": [
    "Création d'un jeu d'apprentissage et de test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "intensive-bidding",
   "metadata": {},
   "outputs": [],
   "source": [
    "X=kg['claimReview_claimReviewed']\n",
    "y=kg['ratingValue']\n",
    "\n",
    "X_train,X_test,y_train,y_test=train_test_split(X, y, \n",
    "                                               train_size=0.7 ,\n",
    "                                               random_state=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "central-double",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(\n",
    "            lowercase=False,\n",
    "            ngram_range=(2,2),\n",
    "            tokenizer=None,\n",
    "            preprocessor=lambda x:x,\n",
    "            min_df=0.01, \n",
    "            max_df=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "informal-virus",
   "metadata": {},
   "source": [
    "Création du pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "proper-possible",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pipeline créé\n"
     ]
    }
   ],
   "source": [
    "pipe = Pipeline([(\"cleaner\", TextPreTraitement(stopword=True)),\n",
    "                 (\"count_vectorizer\", vectorizer),\n",
    "                 (\"SVM\", SVC())])\n",
    "pipe.fit(X_train,y_train)\n",
    "\n",
    "print(\"pipeline créé\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fitted-default",
   "metadata": {},
   "source": [
    "On teste le modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "grateful-loading",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train accuracy: 0.4261185682326622\n",
      "test accuracy: 0.438862064465614\n"
     ]
    }
   ],
   "source": [
    "y_pred = pipe.predict(X_test)\n",
    "\n",
    "print(\"train accuracy:\",accuracy_score(y_train, pipe.predict(X_train)))\n",
    "print(\"test accuracy:\",accuracy_score(y_test, y_pred))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
